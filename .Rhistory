reshape(intend0, direction = 'long')
library(reshape2)
melt(intend0)
View(melt(intend0))
health_media1 <- fread('../6-health-media1.csv')
health_media2 <- fread('../6-health-media2.csv')
health_media3 <- fread('../6-health-media3.csv')
health_media4 <- fread('../6-health-media4.csv')
intend0 <- list(health_media1$INTEND.0, health_media2$INTEND.0, health_media3$INTEND.0,
health_media4$INTEND.0)
intend0_nrow <- max(sapply(intend0, length))
intend0 <- sapply(intend0, function(x) c(x, rep(NA, intend0_nrow - length(x))))
intend0 <- as.data.frame(intend0)
colnames(intend0) <- c('health_media1', 'health_media2', 'health_media3', 'health_media4')
View(na.omit(melt(intend0)))
View(na.omit(melt(intend0)))
intend0 <- na.omit(melt(intend0))
View(intend0)
colnames(intend0) <- c('health_media', 'INTEND.0')
View(intend0)
oneway.test(intend0$INTEND.0 ~ intend0$health_media, var.equal = TRUE)
oneway_test <- oneway.test(intend0$INTEND.0 ~ intend0$health_media, var.equal = TRUE)
oneway_test$statistic
oneway_test$parameter
oneway_test$parameter[1]
oneway_test$parameter[2]
cut_off_95 <- qf(p = 0.95, df1 = oneway_test$parameter[1], df2 = oneway_test$parameter[2])
cut_off_95
cut_off_99 <- qf(p = 0.99, df1 = oneway_test$parameter[1], df2 = oneway_test$parameter[2])
cut_off_99
health_media1 <- fread('../6-health-media1.csv')
health_media2 <- fread('../6-health-media2.csv')
health_media3 <- fread('../6-health-media3.csv')
health_media4 <- fread('../6-health-media4.csv')
intend0 <- list(health_media1$INTEND.0, health_media2$INTEND.0, health_media3$INTEND.0,
health_media4$INTEND.0)
intend0_nrow <- max(sapply(intend0, length))
intend0 <- sapply(intend0, function(x) c(x, rep(NA, intend0_nrow - length(x))))
intend0 <- as.data.frame(intend0)
colnames(intend0) <- c('health_media1', 'health_media2', 'health_media3', 'health_media4')
intend0_row_wise <- na.omit(melt(intend0))
colnames(intend0_row_wise) <- c('health_media', 'INTEND.0')
oneway_test <- oneway.test(intend0_row_wise$INTEND.0 ~ intend0_row_wise$health_media,
var.equal = TRUE)
cut_off_95 <- qf(p = 0.95, df1 = oneway_test$parameter[1], df2 = oneway_test$parameter[2])
cut_off_95
cut_off_99 <- qf(p = 0.99, df1 = oneway_test$parameter[1], df2 = oneway_test$parameter[2])
cut_off_99
plot(density(intend0$health_media1))
plot(density(intend0$health_media1), na.rm = TRUE)
plot(density(intend0$health_media1, na.rm = TRUE))
plot(density(intend0$health_media1, na.rm = TRUE), lwd = 2, bty = 'l',
main = 'Distribution of Intention to Share Across All 4 Media')
lines(density(intend0$health_media2, na.rm = TRUE), col = 'blue', lwd = 2)
plot(density(intend0$health_media1, na.rm = TRUE), lwd = 2, bty = 'l', ylim = c(0, 0.3),
main = 'Distribution of Intention to Share Across All 4 Media')
lines(density(intend0$health_media2, na.rm = TRUE), col = 'blue', lwd = 2)
lines(density(intend0$health_media3, na.rm = TRUE), col = 'red', lwd = 2)
lines(density(intend0$health_media4, na.rm = TRUE), col = 'orange', lwd = 2)
legend('topleft', col = c('black', 'blue', 'red', 'orange'), bty = 'n',
legend = c('health_media1', 'health_media2', 'health_media3', 'health_media4'))
plot(density(intend0$health_media1, na.rm = TRUE), lwd = 2, bty = 'l', ylim = c(0, 0.3),
main = 'Distribution of Intention to Share Across All 4 Media')
lines(density(intend0$health_media2, na.rm = TRUE), col = 'blue', lwd = 2)
lines(density(intend0$health_media3, na.rm = TRUE), col = 'red', lwd = 2)
lines(density(intend0$health_media4, na.rm = TRUE), col = 'orange', lwd = 2)
legend('topleft', lwd = c(2, 2, 2, 2), col = c('black', 'blue', 'red', 'orange'),
bty = 'n',
legend = c('health_media1', 'health_media2', 'health_media3', 'health_media4'))
sapply(intend0, var, na.rm = TRUE)
boot_anova <- function(t1, t2, t3, t4, treat_nums) {
size1 <- length(t1)
size2 <- length(t2)
size3 <- length(t3)
size4 <- length(t4)
null_grp1 <- sample(t1 - mean(t1), size1, replace = TRUE)
null_grp2 <- sample(t2 - mean(t2), size2, replace = TRUE)
null_grp3 <- sample(t3 - mean(t3), size3, replace = TRUE)
null_grp4 <- sample(t4 - mean(t4), size4, replace = TRUE)
null_values <- c(null_grp1, null_grp2, null_grp3, null_grp4)
alt_grp1 <- sample(t1, size1, replace = TRUE)
alt_grp2 <- sample(t2, size2, replace = TRUE)
alt_grp3 <- sample(t3, size3, replace = TRUE)
alt_grp4 <- sample(t4, size4, replace = TRUE)
alt_values <- c(alt_grp1, alt_grp2, alt_grp3, alt_grp4)
return(c(oneway.test(null_values ~ treat_nums, var.equal = TRUE)$statistic,
oneway.test(alt_values ~ treat_nums, var.equal = TRUE)$statistic))
}
intend0_1 <- intend0_row_wise$INTEND.0[intend0_row_wise$health_media == 'health_media1']
intend0_2 <- intend0_row_wise$INTEND.0[intend0_row_wise$health_media == 'health_media2']
intend0_3 <- intend0_row_wise$INTEND.0[intend0_row_wise$health_media == 'health_media3']
intend0_4 <- intend0_row_wise$INTEND.0[intend0_row_wise$health_media == 'health_media4']
health_medias <- intend0_row_wise$health_media
set.seed(1)
f_values <- replicate(10000, boot_anova(intend0_1, intend0_2, intend0_3, intend0_4,
health_medias))
f_nulls <- f_values[1, ]
f_alts <- f_values[2, ]
boot_cut_off_95 <- quantile(f_nulls, 0.95)
boot_cut_off_95
boot_cut_off_99 <- quantile(f_nulls, 0.99)
boot_cut_off_99
plot(density(f_nulls), col = 'blue', lwd = 2, main = 'Null and Alt Distributions of F')
plot(density(f_nulls), col = 'blue', lwd = 2, bty = 'l',
main = 'Null and Alt Distributions of F')
lines(density(f_alts), col = 'red', lwd = 2)
plot(density(f_alts), col = 'red', lwd = 2)
plot(density(f_nulls), col = 'blue', lwd = 2, bty = 'l', xlim = c(0, 20),
main = 'Null and Alt Distributions of F')
lines(density(f_alts), col = 'red', lwd = 2)
abline(v = boot_cut_off_95, lty = 2, col = 'blue')
abline(v = boot_cut_off_99, lty = 3, col = 'blue')
abline(v = mean(f_alts), lty = 2, col = 'red')
legend('topright', bty = 'n', lty = c(1, 1, 2, 3, 2),
col = c('blue', 'red', 'blue', 'blue', 'red'),
legend =
c('f_nulls', 'f_alts', 'boot_cut_off_95', 'boot_cut_off_99', 'mean(f_alts)'))
plot(density(f_nulls), col = 'blue', lwd = 2, bty = 'l', xlim = c(0, 20),
main = 'Null and Alt Distributions of F')
lines(density(f_alts), col = 'red', lwd = 2)
abline(v = boot_cut_off_95, lty = 2, col = 'blue')
abline(v = boot_cut_off_99, lty = 3, col = 'blue')
abline(v = mean(f_alts), lty = 2, col = 'red')
legend('topright', bty = 'n', lty = c(1, 1, 2, 3, 2), lwd = c(2, 2, 1, 1, 1),
col = c('blue', 'red', 'blue', 'blue', 'red'),
legend =
c('f_nulls', 'f_alts', 'boot_cut_off_95', 'boot_cut_off_99', 'mean(f_alts)'))
15*7
15+12*6
87 -35
mean(6125, 4765, 5700, 6800, 3630, 5300, 5450)
mean(1, 2, 3, 4)
mean(c(6125, 4765, 5700, 6800, 3630, 5300, 5450))
library(swirl)
swirl()
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date('1969-01-01')
unclass(d2)
install.packages('manipulate')
library(manipulate)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
interactive_regression <- function() {
cat("Click on the plot to create data points; hit [esc] to stop")
plot(NA, xlim=c(-5,50), ylim=c(-5,50))
points = data.frame()
repeat {
click_loc <- locator(1)
if (is.null(click_loc)) break
if(nrow(points) == 0 ) {
points <- data.frame(x=click_loc$x, y=click_loc$y)
} else {
points <- rbind(points, c(click_loc$x, click_loc$y))
}
plot(points, xlim=c(-5,50), ylim=c(-5,50), pch=19, col="gray")
if (nrow(points) < 2) next
model <- lm(points$y ~ points$x)
abline(model, lwd=2, col="cornflowerblue")
text(1, 50, paste(c("Raw intercept: ", round(model$coefficients[1], 2)), collapse=" "))
text(1, 45, paste(c("Raw slope    : ", round(model$coefficients[2], 2)), collapse=" "))
text(1, 40, paste(c("Correlation  : ", round(cor(points$x, points$y), 2)), collapse=" "))
}
return(points)
}
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
interactive_regression()
pts <- interactive_regression()
pts <- interactive_regression()
pts <- interactive_regression()
pts
pts
pts <- interactive_regression()
summary(lm(pts$y ~ pts$x))
cor(pts)
cor(pts$y, pts$x)
summ <- summary(lm(pts$y ~ pts$x))
summ$coefficients
summ$coefficients[1]
summ$coefficients[2]
summ$coefficients[, 2]
summ$coefficients[1, ]
summ$coefficients[, 1]
summ$coefficients[1, 1]
summ$coefficients[2, 1]
summ$coefficients[, 1]
interactive_regression()
pts_std <- scale(pts)
pts_std <- as.data.frame(pts_std)
summary(lm(pts_std$y ~ pts_std$x))
summary(lm(pts$y ~ pts$x))
setwd("F:/IMBA/4th semester/4-thesis/piccollage_iss_etl/r")
library(recommenderlab)
library(data.table)
library(ggplot2)
convert_to_matrix <- function(tail = '', date_of_data = '2017-03-29') {
file <- fread(paste('../data/', date_of_data, '/accounts_bundles_matrix_final', tail,
'.csv', sep = ''))
account_id <- rep(file$account_id, each = ncol(file) - 1)
bundle_id <- rep(colnames(file)[2:ncol(file)], times = nrow(file))
bundle_usage <- as.numeric(as.matrix(t(file[, 2:ncol(file)])))
bundle_usage <- ifelse(bundle_usage == 0, NA, bundle_usage)
file <- cbind.data.frame(account_id, bundle_id, bundle_usage)
file <- file[complete.cases(file), ]
file <- file[order(file$account_id), ]
file <- as(file, 'realRatingMatrix')
usage_bundles <- file[, colCounts(file) > 1] # user dulu baru bundle
usage_bundles <- usage_bundles[rowCounts(usage_bundles) > 1, ]
return(usage_bundles)
}
sampling_method <- 'cross-validation'
n_eval <- 10
bundles_to_keep <- 2
usage_threshold <- 2
n_recommendations <- c(3, 6, 9)
models_to_evaluate <- list(
IBCF_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'Z-score',
k = 15)),
IBCF_adj_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'center',
k = 15)),
IBCF_cor = list(name = 'IBCF', param = list(method = 'pearson', k = 15)),
Random = list(name = 'RANDOM', param = NULL)
)
set.seed(0)
eval_sets <- evaluationScheme(data = usage_bundles, method = sampling_method, k = n_eval,
given = bundles_to_keep, goodRating = usage_threshold)
usage_bundles <- convert_to_matrix()
usage_bundles
set.seed(0)
eval_sets <- evaluationScheme(data = usage_bundles, method = sampling_method, k = n_eval,
given = bundles_to_keep, goodRating = usage_threshold)
eval_recommender <- Recommender(data = getData(eval_sets, 'train'), method = 'IBCF',
parameter = list(method = 'cosine', normalize = 'center',
k = 15))
model_details <- getModel(eval_recommender)
View(as(model_details$sim, 'matrix'))
eval_prediction <- predict(object = eval_recommender,
newdata = getData(eval_sets, 'known'), type = 'ratings')
View(as(eval_prediction, 'data.frame'))
prediction_matrix <- as.data.frame(as(eval_prediction@data, 'matrix'))
View(prediction_matrix)
k_to_test <- 2:ceiling(ncol(usage_bundles) / 2)
results <- evaluate(x = eval_sets, method = model_to_evaluate, n = k_to_test)
results <- evaluate(x = eval_sets, method = models_to_evaluate, n = k_to_test)
columns_to_sum <- c('precision', 'recall')
summed <- Reduce('+', getConfusionMatrix(results))[, columns_to_sum]
results <- evaluate(x = eval_sets, method = 'IBCF', n = k_to_test)
columns_to_sum <- c('precision', 'recall')
summed <- Reduce('+', getConfusionMatrix(results))[, columns_to_sum]
table_performance <- data.table(k = k_to_test, precision = summed[, 1],
recall = summed[, 2])
head(summed)
head(table_performance)
qplot(table_performance[, k], table_performance[, precision]) +
scale_y_continuous(labels = convToPerc)
convToPerc <- function(x) {
paste0(round(x * 100), '%')
}
qplot(table_performance[, k], table_performance[, precision]) +
scale_y_continuous(labels = convToPerc)
qplot(table_performance[, k], table_performance[, recall]) +
scale_y_continuous(labels = convToPerc)
qplot(table_performance[, k], table_performance[, precision]) +
scale_y_continuous(labels = convToPerc)
qplot(table_performance[, k], table_performance[, precision]) +
scale_y_continuous(labels = convToPerc) +
xlab('Number of Neighbors') +
ylab('Precision')
convert_to_matrix <- function(tail = '', date_of_data = '2017-03-29') {
file <- fread(paste('../data/', date_of_data, '/accounts_bundles_matrix_final', tail,
'.csv', sep = ''))
account_id <- rep(file$account_id, each = ncol(file) - 1)
bundle_id <- rep(colnames(file)[2:ncol(file)], times = nrow(file))
bundle_usage <- as.numeric(as.matrix(t(file[, 2:ncol(file)])))
bundle_usage <- ifelse(bundle_usage == 0, NA, bundle_usage)
file <- cbind.data.frame(account_id, bundle_id, bundle_usage)
file <- file[complete.cases(file), ]
file <- file[order(file$account_id), ]
file <- as(file, 'realRatingMatrix')
usage_bundles <- file[, colCounts(file) > 1] # user dulu baru bundle
usage_bundles <- usage_bundles[rowCounts(usage_bundles) > 1, ]
return(usage_bundles)
}
sampling_method <- 'cross-validation'
n_eval <- 10
bundles_to_keep <- 2
usage_threshold <- 2
n_recommendations <- c(3, 6, 9)
k <- 16
models_to_evaluate <- list(
IBCF_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'Z-score',
k = k)),
IBCF_adj_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'center',
k = k)),
IBCF_cor = list(name = 'IBCF', param = list(method = 'pearson', k = k)),
Random = list(name = 'RANDOM', param = NULL)
)
usage_bundles <- convert_to_matrix()
usage_bundles
set.seed(0)
eval_sets <- evaluationScheme(data = usage_bundles, method = sampling_method, k = n_eval,
given = bundles_to_keep, goodRating = usage_threshold)
eval_recommender <- Recommender(data = getData(eval_sets, 'train'), method = 'IBCF',
parameter = list(method = 'cosine', normalize = 'center',
k = 16))
eval_prediction <- predict(object = eval_recommender,
newdata = getData(eval_sets, 'known'), type = 'ratings')
prediction_matrix <- as.data.frame(as(eval_prediction@data, 'matrix'))
View(prediction_matrix)
nrow(getData(eval_sets, 'train'))
nrow(getData(eval_sets, 'known'))
usage_bundles
13023/14471
convert_to_matrix <- function(tail = '', date_of_data = '2017-03-29') {
file <- fread(paste('../data/', date_of_data, '/accounts_bundles_matrix_final', tail,
'.csv', sep = ''))
account_id <- rep(file$account_id, each = ncol(file) - 1)
bundle_id <- rep(colnames(file)[2:ncol(file)], times = nrow(file))
bundle_usage <- as.numeric(as.matrix(t(file[, 2:ncol(file)])))
bundle_usage <- ifelse(bundle_usage == 0, NA, bundle_usage)
file <- cbind.data.frame(account_id, bundle_id, bundle_usage)
file <- file[complete.cases(file), ]
file <- file[order(file$account_id), ]
file <- as(file, 'realRatingMatrix')
usage_bundles <- file[, colCounts(file) > 1] # user dulu baru bundle
usage_bundles <- usage_bundles[rowCounts(usage_bundles) > 1, ]
return(usage_bundles)
}
sampling_method <- 'bootstrap'
percentage_training <- 0.8
n_eval <- 10
bundles_to_keep <- 2
usage_threshold <- 2
n_recommendations <- c(3, 6, 9)
k <- 16
models_to_evaluate <- list(
IBCF_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'Z-score',
k = k)),
IBCF_adj_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'center',
k = k)),
IBCF_cor = list(name = 'IBCF', param = list(method = 'pearson', k = k)),
Random = list(name = 'RANDOM', param = NULL)
)
usage_bundles <- convert_to_matrix()
usage_bundles
set.seed(0)
eval_sets <- evaluationScheme(data = usage_bundles, method = sampling_method, k = n_eval,
given = bundles_to_keep, goodRating = usage_threshold,
train = percentage_training
)
nrow(getData(eval_sets, 'train'))
nrow(getData(eval_sets, 'known'))
usage_bundles
nrow(getData(eval_sets, 'train')) / 14471
source('F:/IMBA/4th semester/4-thesis/piccollage_iss_etl/r/2-recommendation_model.R')
convert_to_matrix <- function(tail = '', date_of_data = '2017-03-29') {
file <- fread(paste('../data/', date_of_data, '/accounts_bundles_matrix_final', tail,
'.csv', sep = ''))
account_id <- rep(file$account_id, each = ncol(file) - 1)
bundle_id <- rep(colnames(file)[2:ncol(file)], times = nrow(file))
bundle_usage <- as.numeric(as.matrix(t(file[, 2:ncol(file)])))
bundle_usage <- ifelse(bundle_usage == 0, NA, bundle_usage)
file <- cbind.data.frame(account_id, bundle_id, bundle_usage)
file <- file[complete.cases(file), ]
file <- file[order(file$account_id), ]
file <- as(file, 'realRatingMatrix')
usage_bundles <- file[, colCounts(file) > 1] # user dulu baru bundle
usage_bundles <- usage_bundles[rowCounts(usage_bundles) > 1, ]
return(usage_bundles)
}
sampling_method <- 'cross-validation'
n_eval <- 10
bundles_to_keep <- 2
usage_threshold <- 2
n_recommendations <- c(3, 6, 9)
k <- 16
models_to_evaluate <- list(
IBCF_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'Z-score',
k = k)),
IBCF_adj_cos = list(name = 'IBCF', param = list(method = 'cosine', normalize = 'center',
k = k)),
IBCF_cor = list(name = 'IBCF', param = list(method = 'pearson', k = k)),
Random = list(name = 'RANDOM', param = NULL)
)
usage_bundles <- convert_to_matrix()
library(recommenderlab)
library(data.table)
library(ggplot2)
usage_bundles <- convert_to_matrix()
usage_bundles
set.seed(0)
eval_sets <- evaluationScheme(data = usage_bundles, method = sampling_method, k = n_eval,
given = bundles_to_keep, goodRating = usage_threshold
# , train = percentage_training
)
eval_recommender <- Recommender(data = getData(eval_sets, 'train'), method = 'IBCF',
parameter = list(method = 'cosine', normalize = 'center',
k = 16))
eval_prediction <- predict(object = eval_recommender,
newdata = getData(eval_sets, 'known'), type = 'ratings')
prediction_matrix <- as.data.frame(as(eval_prediction@data, 'matrix'))
5 ^ 2
5 ** 2
setwd("F:/IMBA/4th semester/1-business analytics using statistical modeling/business_analytics_using_statistical_modeling")
auto <- read.table("../10-auto-data.txt", header = FALSE, na.strings = "?")
names(auto) <- c("mpg", "cylinders", "displacement", "horsepower", "weight",
"acceleration", "model_year", "origin", "car_name")
names(auto) <- c("mpg", "cyl", "disp", "hp", "w", "acc", "year", "ori", "name")
View(auto)
auto_cor <- cor(auto[1:8], use = 'pairwise.complete.obs')
auto_cor
auto_cor <- round(cor(auto[1:8], use = 'pairwise.complete.obs'), 2)
auto_cor
names(auto) <- c("mpg", "cylinders", "displacement", "horsepower", "weight",
"acceleration", "model_year", "origin", "car_name")
auto_cor <- round(cor(auto[1:8], use = 'pairwise.complete.obs'), 2)
auto_cor
names(auto) <- c("mpg", "cyl", "disp", "hp", "weight", "acc", "year", "ori", "name")
auto_cor <- round(cor(auto[1:8], use = 'pairwise.complete.obs'), 2)
auto_cor
library(knitr)
kable(auto_cor)
kable(auto_cor)
kable(auto_cor)
plot(auto[c(1)])
plot(auto[c(-9)])
plot(auto)
par(mfrow = c(3, 3))
for(i in 2:8) {
plot(auto[, i], auto$mpg, main = paste('mpg vs. ', names(auto)[i]), ylab = 'mpg',
xlab = names(auto)[i])
}
for(i in 2:8) {
plot(auto[, i], auto$mpg, main = paste('mpg vs. ', names(auto)[i]), ylab = 'mpg',
xlab = names(auto)[i])
}
par(mfrow = c(3, 3))
for(i in 2:8) {
plot(auto[, i], auto$mpg, main = paste('mpg vs. ', names(auto)[i]), ylab = 'mpg',
xlab = names(auto)[i])
}
par(mfrow = c(1, 1))
par(mfrow = c(3, 3))
for(i in 2:8) {
plot(auto[, i], auto$mpg, main = paste('mpg vs. ', names(auto)[i]), ylab = 'mpg',
xlab = names(auto)[i])
}
regr_mpg <- lm(mpg ~ cyl + disp + hp + weight + acc + year + factor(ori), data = auto)
summary(regr_mpg)
auto_std <- data.frame(scale(auto[c(1:7)]))
auto_std$ori <- auto$ori
regr_mpg_std <- lm(mpg ~ cyl + disp + hp + weight + acc + year + factor(ori), data = auto)
summary(regr_mpg_std)
regr_mpg_std <- lm(mpg ~ cyl + disp + hp + weight + acc + year + factor(ori),
data = auto_std)
summary(regr_mpg_std)
names(auto_std)[2]
sapply(auto_std[, c(2:8)], function(x) {
summary(lm(auto_std$mpg ~ x))
})
sapply(auto_std[, c(2:8)], function(x) {
summary(lm(auto_std$mpg ~ x))
print('###############################################################################')
})
sapply(auto_std[, c(2:8)], function(x) {
print('###############################################################################')
return(summary(lm(auto_std$mpg ~ x)))
})
summary(regr_mpg_std)
sapply(auto_std[, c(2, 4, 6)], function(x) {
summary(lm(auto_std$mpg ~ x))
})
plot(density(regr_mpg$residuals))
plot(density(regr_mpg_std$residuals), main = 'Standardized Linear Regression')
plot(density(regr_mpg$residuals), main = 'Ordinary Linear Regression')
abline(v = 0, col = 'blue')
plot(density(regr_mpg_std$residuals), main = 'Standardized Linear Regression')
abline(v = 0, col = 'blue')
diag(auto_cor) <- NA
auto_cor_melt <- melt(auto_cor)
View(auto_cor_melt)
high_cor <- auto_cor_melt[auto_cor_melt$value > 0.7]
high_cor <- auto_cor_melt[auto_cor_melt$value > 0.7, ]
View(high_cor)
auto_cor_melt <- auto_cor_melt[complete.cases(auto_cor_melt), ]
View(auto_cor_melt)
high_cor <- auto_cor_melt[auto_cor_melt$value > 0.7, ]
View(high_cor)
high_cor <- high_cor[!duplicated(high_cor), ]
library(gtools)
?combinations
high_cor[1:2]
apply(high_cor[1:2], 1, sort)
t(apply(high_cor[1:2], 1, sort))
high_cor[, 1:2]
View(high_cor)
high_cor[, 1:2] <- t(apply(high_cor[, 1:2], 1, sort))
high_cor <- high_cor[!duplicated(high_cor), ]
View(high_cor)
install.packages('pander')
library(pander)
pandoc.table(auto_cor, style = 'rmarkdown', justify = 'right')
pandoc.table(auto_cor, style = 'rmarkdown', justify = 'right', plain.ascii = TRUE)
